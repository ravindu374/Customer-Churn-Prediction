{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiTdz5VGrGM5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '--------------------------'\n",
        "# Load dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# First look at data\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "display(df.head())\n",
        "\n",
        "# Data types and null values\n",
        "print(\"\\nInfo:\")\n",
        "print(df.info())\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nSummary statistics:\")\n",
        "display(df.describe(include=\"all\"))\n",
        "\n",
        "# Missing values check\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "#numerical variables\n",
        "num = list(df.select_dtypes(include=['int64','float64']).keys())\n",
        "\n",
        "#categorical variables\n",
        "cat = list(df.select_dtypes(include='O').keys())\n",
        "\n",
        "print(\"Categorical features: \",cat)\n",
        "print(\"Numerical: \",num)\n",
        "\n",
        "# value_counts of the categorical columns\n",
        "for i in cat:\n",
        "    print(df[i].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Remove cx_id\n",
        "df = df.drop(columns=\"cx_id\")\n",
        "\n",
        "# Ensure numeric columns are clean\n",
        "numeric_cols = ['tenure', 'monthly_bill', 'total_bill']\n",
        "for col in numeric_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df[col] = df[col].astype(\"float\")\n",
        "\n",
        "print(\"Missing values per column after cleansing:\\n\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Encoding categorical variables\n",
        "# First convert all values to string and lowercase (to avoid issues)\n",
        "df['senior_citizen'] = df['senior_citizen'].astype(str).str.lower()\n",
        "\n",
        "# Replace values\n",
        "df['senior_citizen'] = df['senior_citizen'].replace({\n",
        "    'yes': 1, 'y': 1,\n",
        "    'no': 0,  'n': 0\n",
        "})\n",
        "\n",
        "# Finally, ensure integers\n",
        "df['senior_citizen'] = df['senior_citizen'].astype(int)\n",
        "df.head()\n",
        "#categorical variables\n",
        "cat = list(df.select_dtypes(include='O').keys())\n",
        "# value_counts of the categorical columns\n",
        "for i in cat:\n",
        "    print(df[i].value_counts())"
      ],
      "metadata": {
        "id": "30k9nLFfrIQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check again how many missing values\n",
        "print(\"Missing values before filling:\\n\", df.isnull().sum())\n",
        "\n",
        "# Fill numeric columns with median\n",
        "df['tenure'] = df['tenure'].fillna(df['tenure'].mean().round(0))\n",
        "df['monthly_bill'] = df['monthly_bill'].fillna(df['monthly_bill'].mean().round(2))\n",
        "df['total_bill'] = df['total_bill'].fillna(df['total_bill'].mean().round(2))\n",
        "\n",
        "# Fill categorical columns with mode\n",
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "for col in categorical_cols:\n",
        "    df[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "# Check again after filling\n",
        "print(\"\\nMissing values after filling:\\n\", df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "l45oQi_7rMUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Prepare features/labels\n",
        "X = pd.get_dummies(df.drop(columns=['churn']), drop_first=True)\n",
        "y = df['churn']\n",
        "# Train/validation split (stratify keeps original class ratio in both sets)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(\"Class distribution BEFORE balancing (train):\", Counter(y_train))\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n",
        "y_train = y_train_bal\n",
        "print(\"Class distribution AFTER balancing (train):\", Counter(y_train))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "vDHCbFVzrSSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standard libraries for data analysis:----------------------\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "#sklearn modules for Model Selection--------------------------------------\n",
        "\n",
        "from sklearn import svm, tree, linear_model, neighbors\n",
        "from sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "#sklearn modules for Model Evaluation & Improvement---------------------------\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "from sklearn.metrics import make_scorer, recall_score\n"
      ],
      "metadata": {
        "id": "GUhj5Cn1rTdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "\n",
        "sc_X = StandardScaler()\n",
        "X_train = pd.DataFrame(sc_X.fit_transform(X_train_bal))\n",
        "X_train.columns = X_train.columns.values\n",
        "X_train.index = X_train.index.values\n",
        "\n",
        "X_valid = pd.DataFrame(sc_X.transform(X_valid))\n",
        "X_valid.columns = X_valid.columns.values\n",
        "X_valid.index = X_valid.index.values\n",
        "\n",
        "# Convert y_valid to numerical labels\n",
        "y_valid = y_valid.apply(lambda x: 1 if x == 'Yes' else 0)\n"
      ],
      "metadata": {
        "id": "5LfulsyerZXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check each Model for Train data set\n",
        "#Compare Baseline Classification Algorithms - First Iteration\n",
        "#Using Accuracy and ROC AUC Mean Metrics\n",
        "\n",
        "from sklearn import model_selection\n",
        "\n",
        "models = []\n",
        "\n",
        "models.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state = 0,\n",
        "                                                         class_weight='balanced')))\n",
        "\n",
        "models.append(('SVC', SVC(kernel = 'linear', random_state = 0)))\n",
        "\n",
        "\n",
        "models.append(('Kernel SVM', SVC(kernel = 'rbf', random_state = 0)))\n",
        "\n",
        "\n",
        "models.append(('KNN', KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)))\n",
        "\n",
        "\n",
        "models.append(('Gaussian NB', GaussianNB()))\n",
        "\n",
        "\n",
        "models.append(('Decision Tree Classifier',\n",
        "               DecisionTreeClassifier(criterion = 'entropy', random_state = 0)))\n",
        "\n",
        "\n",
        "models.append(('Random Forest', RandomForestClassifier(\n",
        "    n_estimators=100, criterion = 'entropy', random_state = 0)))\n",
        "\n",
        "#Evaluating Model Results:\n",
        "acc_results = []\n",
        "auc_results = []\n",
        "names = []\n",
        "# set table to table to populate with performance results\n",
        "col = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD',\n",
        "       'Accuracy Mean', 'Accuracy STD']\n",
        "\n",
        "model_results = pd.DataFrame(columns=col)\n",
        "i = 0\n",
        "# evaluate each model using k-fold cross-validation\n",
        "for name, model in models:\n",
        "    kfold = model_selection.KFold(\n",
        "        n_splits=10, random_state=None)  # 10-fold cross-validation\n",
        "\n",
        "    cv_acc_results = model_selection.cross_val_score(  # accuracy scoring\n",
        "        model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
        "\n",
        "    cv_auc_results = model_selection.cross_val_score(  # roc_auc scoring\n",
        "        model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
        "\n",
        "    acc_results.append(cv_acc_results)\n",
        "    auc_results.append(cv_auc_results)\n",
        "    names.append(name)\n",
        "    model_results.loc[i] = [name,\n",
        "                         round(cv_auc_results.mean()*100, 2),\n",
        "                         round(cv_auc_results.std()*100, 2),\n",
        "                         round(cv_acc_results.mean()*100, 2),\n",
        "                         round(cv_acc_results.std()*100, 2)\n",
        "                         ]\n",
        "    i += 1\n",
        "\n",
        "model_results.sort_values(by=['ROC AUC Mean'], ascending=False)"
      ],
      "metadata": {
        "id": "DN1bOnWrrb40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check each Model for Test data set\n",
        "#Logistic Regression\n",
        "\n",
        "# Fitting Logistic Regression to the Training set\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_valid)\n",
        "y_pred = pd.Series(y_pred).apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "\n",
        "#Evaluate results\n",
        "\n",
        "acc = accuracy_score(y_valid, y_pred )\n",
        "prec = precision_score(y_valid, y_pred )\n",
        "rec = recall_score(y_valid, y_pred )\n",
        "f1 = f1_score(y_valid, y_pred )\n",
        "f2 = fbeta_score(y_valid, y_pred, beta=2.0)\n",
        "\n",
        "results = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "\n",
        "\n",
        "#Support Vector Machine (linear classifier)\n",
        "\n",
        "\n",
        "# Fitting SVM (SVC class) to the Training set:\n",
        "\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_valid)\n",
        "y_pred = pd.Series(y_pred).apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "#Evaluate results\n",
        "\n",
        "acc = accuracy_score(y_valid, y_pred )\n",
        "prec = precision_score(y_valid, y_pred )\n",
        "rec = recall_score(y_valid, y_pred)\n",
        "f1 = f1_score(y_valid, y_pred )\n",
        "f2 = fbeta_score(y_valid, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "results = pd.concat([results,model_results],ignore_index=True)\n",
        "\n",
        "#K-Nearest Neighbours\n",
        "\n",
        "\n",
        "# Fitting KNN to the Training set:\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors = 22, metric = 'minkowski', p = 2)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred  = classifier.predict(X_valid)\n",
        "y_pred = pd.Series(y_pred).apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "#Evaluate results\n",
        "acc = accuracy_score(y_valid, y_pred )\n",
        "prec = precision_score(y_valid, y_pred )\n",
        "rec = recall_score(y_valid, y_pred )\n",
        "f1 = f1_score(y_valid, y_pred )\n",
        "f2 = fbeta_score(y_valid, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['K-Nearest Neighbours', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = pd.concat([results,model_results],ignore_index=True)\n",
        "\n",
        "\n",
        "#Kernel SVM\n",
        "\n",
        "# Fitting Kernel SVM to the Training set:\n",
        "\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_valid)\n",
        "y_pred = pd.Series(y_pred).apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "#Evaluate results\n",
        "\n",
        "acc = accuracy_score(y_valid, y_pred )\n",
        "prec = precision_score(y_valid, y_pred )\n",
        "rec = recall_score(y_valid, y_pred )\n",
        "f1 = f1_score(y_valid, y_pred )\n",
        "f2 = fbeta_score(y_valid, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['Kernel SVM', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = pd.concat([results,model_results],ignore_index=True)\n",
        "\n",
        "#Naive Byes\n",
        "\n",
        "# Fitting Naive Byes to the Training set:\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_valid)\n",
        "y_pred = pd.Series(y_pred).apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "#Evaluate results\n",
        "acc = accuracy_score(y_valid, y_pred )\n",
        "prec = precision_score(y_valid, y_pred )\n",
        "rec = recall_score(y_valid, y_pred )\n",
        "f1 = f1_score(y_valid, y_pred )\n",
        "f2 = fbeta_score(y_valid, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['Naive Byes', acc, prec, rec, f1, f2]],\n",
        "                columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = pd.concat([results,model_results],ignore_index=True)\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "\n",
        "# Fitting Decision Tree to the Training set:\n",
        "\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_valid)\n",
        "y_pred = pd.Series(y_pred).apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "#Evaluate results\n",
        "acc = accuracy_score(y_valid, y_pred )\n",
        "prec = precision_score(y_valid, y_pred )\n",
        "rec = recall_score(y_valid, y_pred )\n",
        "f1 = f1_score(y_valid, y_pred )\n",
        "f2 = fbeta_score(y_valid, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['Decision Tree', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = pd.concat([results,model_results],ignore_index=True)\n",
        "\n",
        "#Random Forest\n",
        "\n",
        "# Fitting Random Forest to the Training set:\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators = 72, criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_valid)\n",
        "y_pred = pd.Series(y_pred).apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "#Evaluate results\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "acc = accuracy_score(y_valid, y_pred )\n",
        "prec = precision_score(y_valid, y_pred )\n",
        "rec = recall_score(y_valid, y_pred )\n",
        "f1 = f1_score(y_valid, y_pred )\n",
        "f2 = fbeta_score(y_valid, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = pd.concat([results,model_results],ignore_index=True)"
      ],
      "metadata": {
        "id": "Bo6Sdde1regM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train & evaluate Chosen Model\n",
        "\n",
        "# Fit Logistic Regression on the Training dataset:\n",
        "\n",
        "classifier = LogisticRegression(random_state = 0, penalty = 'l2')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the Test set results\n",
        "\n",
        "y_pred = classifier.predict(X_valid)\n",
        "y_pred = pd.Series(y_pred).apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "#Evaluate Model Results on Test Set:\n",
        "\n",
        "acc = accuracy_score(y_valid, y_pred )\n",
        "prec = precision_score(y_valid, y_pred )\n",
        "rec = recall_score(y_valid, y_pred )\n",
        "f1 = f1_score(y_valid, y_pred )\n",
        "f2 = fbeta_score(y_valid, y_pred, beta=2.0)\n",
        "\n",
        "results = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "print (results)"
      ],
      "metadata": {
        "id": "DtoznqiBrix2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-check k-Fold Cross Validation:\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "print(\"Logistic Regression Classifier Accuracy: %0.2f (+/- %0.2f)\"  % (accuracies.mean(), accuracies.std() * 2))"
      ],
      "metadata": {
        "id": "9anB9-pvrlVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper parameter Tuning\n",
        "\n",
        "\n",
        "# First Iteration:\n",
        "\n",
        "# Select Regularization Method\n",
        "penalty = ['l1', 'l2']\n",
        "\n",
        "# Create regularization hyperparameter space\n",
        "C = [0.001, 0.01, 0.1, 1, 1.5, 10, 100]\n",
        "\n",
        "# Combine Parameters\n",
        "parameters = dict(C=C, penalty=penalty)\n",
        "\n",
        "lr_classifier = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = \"balanced_accuracy\",\n",
        "                           cv = 10,\n",
        "                           n_jobs = -1)\n",
        "\n",
        "lr_classifier  = lr_classifier .fit(X_train, y_train)\n",
        "\n",
        "lr_best_accuracy = lr_classifier.best_score_\n",
        "lr_best_parameters = lr_classifier.best_params_\n",
        "lr_best_accuracy, lr_best_parameters\n",
        "\n"
      ],
      "metadata": {
        "id": "3WNowx-zrnbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Second iteration\n",
        "\n",
        "# Select Regularization Method\n",
        "penalty = ['l2']\n",
        "\n",
        "# Create regularization hyperparameter space\n",
        "C = [ 0.12, 0.155, 0.16, 0.18, 0.19]\n",
        "\n",
        "# Combine Parameters\n",
        "parameters = dict(C=C, penalty=penalty)\n",
        "\n",
        "lr_classifier = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = \"balanced_accuracy\",\n",
        "                           cv = 10,\n",
        "                           n_jobs = -1)\n",
        "\n",
        "lr_classifier  = lr_classifier .fit(X_train, y_train)\n",
        "\n",
        "lr_best_accuracy = lr_classifier.best_score_\n",
        "lr_best_parameters = lr_classifier.best_params_\n",
        "lr_best_accuracy, lr_best_parameters\n"
      ],
      "metadata": {
        "id": "iPumMlBqrqGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Hyper parameter tuning and selection\n",
        "\n",
        "lr_classifier = LogisticRegression(penalty = 'l2',C=1)\n",
        "lr_classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Predict the Test set results\n",
        "\n",
        "y_pred = lr_classifier.predict(X_valid)\n",
        "y_pred = pd.Series(y_pred).apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "#probability score\n",
        "y_pred_probs = lr_classifier.predict_proba(X_valid)\n",
        "y_pred_probs  = y_pred_probs [:, 1]\n",
        "\n",
        "#Evaluate results\n",
        "acc = accuracy_score(y_valid, y_pred)\n",
        "prec = precision_score(y_valid, y_pred)\n",
        "rec = recall_score(y_valid, y_pred)\n",
        "f1 = f1_score(y_valid, y_pred)\n",
        "f2 = fbeta_score(y_valid, y_pred, beta=2.0)\n",
        "\n",
        "results = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "results = results.sort_values([\"Precision\", \"Recall\", \"F2 Score\"], ascending = False)\n",
        "\n",
        "\n",
        "print (results)"
      ],
      "metadata": {
        "id": "C7HqebMIrssW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare predictions against test set\n",
        "#Revalidate final results with Confusion Matrix:\n",
        "\n",
        "cm = confusion_matrix(y_valid, y_pred)\n",
        "print (cm)"
      ],
      "metadata": {
        "id": "BnHkVSnKrvgZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}