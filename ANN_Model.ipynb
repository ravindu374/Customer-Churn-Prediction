{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj7n5fJ0r5if"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '------------------------'\n",
        "# Load dataset\n",
        "df = pd.read_csv(file_path)\n",
        "# too see max columns\n",
        "pd.set_option('display.max_columns',None)\n",
        "# print dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Remove cx_id\n",
        "df = df.drop(columns=\"cx_id\")\n",
        "\n",
        "# Ensure numeric columns are clean\n",
        "numeric_cols = ['tenure', 'monthly_bill', 'total_bill']\n",
        "for col in numeric_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df[col] = df[col].astype(\"float\")\n",
        "\n",
        "print(\"Missing values per column after cleansing:\\n\")\n",
        "print(df.isnull().sum())\n",
        "df.head()"
      ],
      "metadata": {
        "id": "id-nmSwcr9Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check again how many missing values\n",
        "print(\"Missing values before filling:\\n\", df.isnull().sum())\n",
        "\n",
        "# Fill numeric columns with median\n",
        "df['tenure'] = df['tenure'].fillna(df['tenure'].mean().round(0))\n",
        "df['monthly_bill'] = df['monthly_bill'].fillna(df['monthly_bill'].mean().round(2))\n",
        "df['total_bill'] = df['total_bill'].fillna(df['total_bill'].mean().round(2))\n",
        "\n",
        "# Fill categorical columns with mode\n",
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "for col in categorical_cols:\n",
        "    df[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "# Check again after filling\n",
        "print(\"\\nMissing values after filling:\\n\", df.isnull().sum())\n",
        "df.head()"
      ],
      "metadata": {
        "id": "sb4RgL3Hr_dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#numerical variables\n",
        "\n",
        "num = list(df.select_dtypes(include=['int64','float64']).keys())\n",
        "#categorical variables\n",
        "cat = list(df.select_dtypes(include='O').keys())\n",
        "\n",
        "print(cat)\n",
        "print(num)"
      ],
      "metadata": {
        "id": "TbfXuvEosB4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# value_counts of the categorical columns\n",
        "for i in cat:\n",
        "    print(df[i].value_counts())\n"
      ],
      "metadata": {
        "id": "jjj88j1fsG3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "# Encoding categorical variables\n",
        "\n",
        "df['multiple_connections'] = le.fit_transform(df['multiple_connections'])\n",
        "# df['multiple_connections'] = df['multiple_connections'].replace({'No':0, 'No phone service':0, 'Yes':1})\n",
        "# First convert all values to string and lowercase (to avoid issues)\n",
        "df['senior_citizen'] = df['senior_citizen'].astype(str).str.lower()\n",
        "\n",
        "# Replace values\n",
        "df['senior_citizen'] = df['senior_citizen'].replace({\n",
        "    'yes': 1, 'y': 1,\n",
        "    'no': 0,  'n': 0\n",
        "})\n",
        "\n",
        "# Finally, ensure integers\n",
        "df['senior_citizen'] = df['senior_citizen'].astype(int)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "yEm0pnf8sJSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# value_counts of the categorical columns\n",
        "for i in cat:\n",
        "    print(df[i].value_counts())"
      ],
      "metadata": {
        "id": "VEW-lGFCsLxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label = LabelEncoder()\n",
        "for i in cat:\n",
        "    df[i] = label.fit_transform(df[i])\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# independent and dependent variables\n",
        "x = df.drop('churn',axis=1)\n",
        "y = to_categorical(df.churn)"
      ],
      "metadata": {
        "id": "Su4jumO2sOhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data into training set and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)"
      ],
      "metadata": {
        "id": "9avH9HTDsQ0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "Vz9XWEX0sTIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# initializing ann\n",
        "model = Sequential()\n",
        "\n",
        "# adding the first input layer and the first hidden layer\n",
        "model.add(Dense(17, kernel_initializer = 'normal', activation = 'relu', input_shape = (17, )))\n",
        "\n",
        "# adding batch normalization and dropout layer\n",
        "model.add(Dropout(rate = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# adding the third hidden layer\n",
        "model.add(Dense(12, kernel_initializer = 'normal', activation = 'relu'))\n",
        "\n",
        "# adding batch normalization and dropout layer\n",
        "model.add(Dropout(rate = 0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# adding the fifth hidden layer\n",
        "model.add(Dense(7, kernel_initializer = 'normal', activation = 'relu'))\n",
        "\n",
        "# adding batch normalization and dropout layer\n",
        "model.add(Dropout(rate = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# adding the output layer\n",
        "model.add(Dense(2, kernel_initializer = 'normal', activation = 'sigmoid'))\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# # fitting the model to the training set\n",
        "\n",
        "# model_history = model.fit(X_train, y_train, validation_split = 0.20, validation_data = (X_test, y_test), epochs = 100)\n",
        "\n",
        "# define early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=10,            # stop after 10 epochs of no improvement\n",
        "                           restore_best_weights=True)\n",
        "\n",
        "# fit model\n",
        "model_history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "ikrM7VtWsVca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt   # usually used together\n",
        "plt.figure(figsize = (12, 6))\n",
        "\n",
        "train_loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "# epoch = range(1, 101)\n",
        "epoch = range(1, len(train_loss) + 1)\n",
        "sns.lineplot(x=epoch, y=train_loss, label = 'Training Loss')\n",
        "sns.lineplot(x=epoch, y=val_loss, label = 'Validation Loss')\n",
        "plt.title('Training and Validation Loss\\n')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pMEhJh_RsYMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12, 6))\n",
        "\n",
        "train_loss = model_history.history['accuracy']\n",
        "val_loss = model_history.history['val_accuracy']\n",
        "epoch = range(1, len(train_loss) + 1)\n",
        "sns.lineplot(x=epoch, y=train_loss, label = 'Training accuracy')\n",
        "sns.lineplot(x=epoch, y=val_loss, label = 'Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy\\n')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JSzD9JllsaOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = model.evaluate(X_test, y_test)[1]\n",
        "print(f'Accuracy of model is {acc}')"
      ],
      "metadata": {
        "id": "TcbjQwXFscqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, show_shapes = True)"
      ],
      "metadata": {
        "id": "4Nv14u40sfGm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}